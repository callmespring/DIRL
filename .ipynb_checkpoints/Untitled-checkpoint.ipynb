{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc4bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import platform, sys, os, pickle, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "# os.chdir(\"C:/Users/test/Dropbox/tml/IHS/simu/simu/results\")\n",
    "sys.path.append(\"C:/Users/test/Dropbox/tml/IHS/simu\") # 引用模块的地址\n",
    "import simu.compute_test_statistics as stat\n",
    "import simu.simulate_data_pd as sim\n",
    "import simu.simu_mean_detect as mean_detect\n",
    "import simu.utilities as uti\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import pprint\n",
    "import pandas as pd\n",
    "# create folder under seed if not existing\n",
    "os.chdir(\"C:/Users/test/Dropbox/tml/IHS/simu/simu\")\n",
    "def setpath(trans_setting, K=None, string=None):\n",
    "    os.chdir(\"C:/Users/test/Dropbox/tml/IHS/simu/simu\")\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "    # if K is not None:\n",
    "    #     path_name = 'results/2x3/K'+str(K)+'/sim_result_trans' + trans_setting + '_reward' + reward_setting + '_gamma' + re.sub(\"\\\\.\", \"\", str(gamma)) +\\\n",
    "    #             '_kappa' + str(kappa) + '_N' + str(N) + '_T'+ str(T)+'clusterws'+str(clustering_warm_start) + 'signal' + str(signal)\n",
    "    # else:\n",
    "    path_name = 'results/2x3/'+string+'/sim_result_trans' + trans_setting + '_reward' + reward_setting + '_gamma' + re.sub(\"\\\\.\", \"\", str(gamma)) +\\\n",
    "              '_kappa' + str(kappa) + '_N' + str(N) + '_T'+ str(T)+'clusterws'+str(clustering_warm_start) + 'signal' + str(signal)\n",
    "    if not os.path.exists(path_name):\n",
    "        os.makedirs(path_name, exist_ok=True)\n",
    "    # path_name += '/sim_result_trans' + trans_setting + '_reward' + reward_setting + '_gamma' + re.sub(\"\\\\.\", \"\", str(gamma)) + \\\n",
    "    #              '_kappa' + str(kappa) + '_N' + str(N) + '_1d_' + str(seed)\n",
    "    # if not os.path.exists(path_name):\n",
    "    #     os.makedirs(path_name, exist_ok=True)\n",
    "    os.chdir(path_name)\n",
    "\n",
    "def save_data(out, seed, K_list=None, string=None):\n",
    "    if type(K_list) is range:\n",
    "        for k in K_list:\n",
    "            setpath(trans_setting,k,string)\n",
    "            tmp = out.models[K_list.index(k)]\n",
    "            file_name = \"seed_\"+str(seed)+\".dat\"\n",
    "            with open(file_name, \"wb\") as f:\n",
    "                pickle.dump({'iter_num' : tmp.iter_num, 'group':tmp.g_index,\n",
    "                             'changepoint' :tmp.changepoints, \n",
    "                             'loss':tmp.loss,\n",
    "                             \"ic\":tmp.IC,\n",
    "                             \"K\":k}, f)\n",
    "    else:\n",
    "        setpath(trans_setting,K_list, string)\n",
    "        tmp = out\n",
    "        file_name = \"seed_\"+str(seed)+\".dat\"\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            pickle.dump({'iter_num' : tmp.iter_num, 'group':tmp.g_index,\n",
    "                         'changepoint' :tmp.changepoints, \n",
    "                         'loss':tmp.loss,\n",
    "                         \"ic\":tmp.IC,\n",
    "                         \"K\":K_list}, f)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "767ce98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "gamma = 0.9\n",
    "trans_setting = 'pwconst2'\n",
    "reward_setting = 'homo'\n",
    "N = int(3*12)\n",
    "\n",
    "np.random.seed(seed)\n",
    "# %% simulate data\n",
    "# terminal timestamp\n",
    "T = 100\n",
    "kappa = T\n",
    "# dimension of X0\n",
    "p = 2\n",
    "# mean vector of X0\n",
    "mean0 = 0\n",
    "# diagonal covariance of X0\n",
    "cov0 = 0.5\n",
    "# mean vector of random errors zt\n",
    "mean = 0\n",
    "# diagonal covariance of random errors zt\n",
    "cov = 0.25\n",
    "\n",
    "# width of smooth transition function\n",
    "w = 0.01\n",
    "delta = 1/10\n",
    "\n",
    "# heter changpoints and means\n",
    "K = 3\n",
    "\n",
    "# parallel\n",
    "nthread=3\n",
    "\n",
    "clustering_warm_start=0\n",
    "\n",
    "coef =[[[0.1, 0.5, 0.5],[0.1, 0.25, 0.75]],\n",
    "        [[0,0.0,0.75],[0,0.25,-0.5], [0.5, 0.1, 0.25]]]\n",
    "signal = [[0.1, -0.1], [0.1, 0, -0.1]]\n",
    "def evaluate(changepoints_true, g_index, predict, N, T):\n",
    "    '''\n",
    "    g_index : predicted group index\n",
    "    predict : predicted changepoints\n",
    "    '''\n",
    "    changepoints_true = changepoints_true.flatten()\n",
    "    changepoint_err = np.mean(np.abs(predict - changepoints_true)/T)\n",
    "    cluster_err = adjusted_rand_score(changepoints_true, g_index)\n",
    "    return changepoint_err, cluster_err\n",
    "def evaluate_Klist(K_list, out,changepoints_true, N, T):\n",
    "    changepoint_err_list=[None] * len(K_list)\n",
    "    cluster_err_list=[None] * len(K_list)\n",
    "    for k in K_list:\n",
    "        tmp = out.models[K_list.index(k)]\n",
    "        changepoint_err_list[K_list.index(k)], cluster_err_list[K_list.index(k)] = evaluate(changepoints_true, tmp.g_index, tmp.changepoints, N, T)\n",
    "    return np.array(changepoint_err_list), np.array(cluster_err_list)\n",
    "\n",
    "def gen_dat(N, T, K, coef, signal, changepoint_list=None,\n",
    "            trans_setting=\"pwsonst2\",\n",
    "            seed=1):\n",
    "    np.random.seed(seed)\n",
    "    if changepoint_list is None:\n",
    "        changepoint_list = [int(T/2) + int(0.1 * T) - 1, int(T/2)-1, int(T/2) - int(0.1 * T) - 1] \n",
    "    changepoints_true = np.zeros([N, 1])\n",
    "    States = np.zeros([N, T, p])\n",
    "    Rewards = np.zeros([N, T-1])\n",
    "    Actions = np.zeros([N, T-1])\n",
    "    def myreward_function(t):\n",
    "        return sim_dat.reward_homo()\n",
    "    coef_tmp = [None] * 2\n",
    "    changepoint = 0\n",
    "    for i in range(N):\n",
    "        if i < int(N/3):\n",
    "            changepoint = changepoint_list[0]\n",
    "            coef_tmp[0] = coef[0][0]\n",
    "            coef_tmp[1] = coef[1][0]\n",
    "            signal_tmp = [signal[0][0], signal[1][0]]\n",
    "            # print('signal_tmp',signal_tmp)\n",
    "        elif i < int(N/2):\n",
    "            changepoint = changepoint_list[1]\n",
    "            coef_tmp[0] = coef[0][0]\n",
    "            coef_tmp[1] = coef[1][1]\n",
    "            signal_tmp = [signal[0][0], signal[1][1]]\n",
    "        elif i < int(2*N/3):\n",
    "            changepoint = changepoint_list[1]\n",
    "            coef_tmp[0] = coef[0][1]\n",
    "            coef_tmp[1] = coef[1][1]\n",
    "            signal_tmp = [signal[0][1], signal[1][1]]\n",
    "        else:\n",
    "            changepoint = changepoint_list[2]\n",
    "            coef_tmp[0] = coef[0][1]\n",
    "            coef_tmp[1] = coef[1][2]\n",
    "            signal_tmp = [signal[0][1], signal[1][2]]\n",
    "            \n",
    "        sim_dat = sim.simulate_data(1, T, p, changepoint, delta)\n",
    "        def mytransition_function(t):\n",
    "            return sim_dat.transition_pwconstant2(t, mean, cov, coef_tmp,signal_tmp)\n",
    "        States0, Rewards0, Actions0 = sim_dat.simulate(mean0, cov0, mytransition_function, myreward_function)\n",
    "        States[i, :, :] = States0\n",
    "        Rewards[i, :] = Rewards0\n",
    "        Actions[i, :] = Actions0\n",
    "        changepoints_true[i, ] = changepoint\n",
    "    # normalize state variables\n",
    "    def transform(x):\n",
    "        return (x - np.mean(x)) / np.std(x)\n",
    "    for i in range(p):\n",
    "        States[:,:,i] = transform(States[:,:,i])\n",
    "    return States, Rewards, Actions, changepoints_true\n",
    "\n",
    "\n",
    "States, Rewards, Actions, changepoints_true = gen_dat(N, T, K, \n",
    "                                                              coef, signal,None,\n",
    "                                                              trans_setting,seed + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0f5d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <_io.FileIO name='seed_0.dat' mode='rb' closefd=True>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\test\\AppData\\Local\\Temp/ipykernel_16264/1754396575.py\", line 16, in <module>\n",
      "ResourceWarning: unclosed file <_io.BufferedReader name='seed_0.dat'>\n"
     ]
    }
   ],
   "source": [
    "C_list =[0, 0.1, 1, 10,100, 1000]\n",
    "M=100\n",
    "# ic\n",
    "init=\"changepoints\"\n",
    "K_list = range(2, 6)\n",
    "ic_list = np.zeros(len(K_list))\n",
    "loss_mat = np.zeros([M, len(K_list)])\n",
    "Kl_mat = np.zeros([M, len(K_list)])\n",
    "c_mat = np.zeros([M, len(K_list)])\n",
    "init = \"\"\n",
    "\n",
    "for seed in range(100):\n",
    "    for K in K_list:\n",
    "        setpath(trans_setting, K = K, string=init)\n",
    "        file_name = \"seed_\"+str(seed)+\".dat\"\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        t = pickle.load(pkl_file)\n",
    "        # ic_list[K_list.index(K)] = uti.IC(t['loss'], t['changepoint'], \n",
    "        #                               t['group'], N, T, K, C)\n",
    "        loss_mat[seed, K_list.index(K)] = t['loss']\n",
    "        Kl_mat[seed, K_list.index(K)] =  K*np.log(np.sum(T-1 -t['changepoint']))\n",
    "        Ck, indicesList, occurCount = np.unique(t['group'], return_index = True,return_counts=True)\n",
    "        c_mat[seed, K_list.index(K)] = occurCount.dot((T-1 -t['changepoint'])[np.s_[indicesList]])/(N*T)*np.log(np.sum(T-1 -t['changepoint']))\n",
    "        pkl_file.close()\n",
    "\n",
    "res_diffC = [None] * len(C_list)\n",
    "for C in C_list:\n",
    "    bestK_list = np.zeros(M)\n",
    "    changepoint_err_list = []\n",
    "    cluster_err_list= []\n",
    "    iter_num =[]\n",
    "    for seed in range(M):\n",
    "        ic_list = loss_mat[seed, :] - Kl_mat[seed, :] + c_mat[seed,:]*C\n",
    "        bestK = K_list[np.where(ic_list == max(ic_list))[0][0]]\n",
    "        bestK_list[seed]=bestK\n",
    "        setpath(trans_setting, K = bestK)\n",
    "        file_name = \"seed_\"+str(seed)+\".dat\"\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        t = pickle.load(pkl_file)\n",
    "        changepoint_err, cluster_err = evaluate(changepoints_true.squeeze(), t['group'].squeeze(),\n",
    "                                                t['changepoint'].squeeze(), N, T)\n",
    "        changepoint_err_list.append(changepoint_err)\n",
    "        cluster_err_list.append(cluster_err)\n",
    "        iter_num.append(t['iter_num'])\n",
    "        pkl_file.close()\n",
    "    res_diffC[C_list.index(C)] = {\"C\":C,\n",
    "                                  \"changepoint_err\": np.mean(changepoint_err_list),\n",
    "                                  \"cluster_err\": np.mean(cluster_err_list),\n",
    "                                  \"iter_num\":np.mean(iter_num),\n",
    "                                  \"bestK\":np.mean(bestK_list),\n",
    "                                  \"cp_var\":np.var(changepoint_err_list),\n",
    "                                  'cluster_var':np.var(cluster_err_list),\n",
    "                                  'iter_num_var':np.var(iter_num),\n",
    "                                  'bestK_var':np.var(bestK_list)}\n",
    "\n",
    "# dat = pd.DataFrame(res_diffC)\n",
    "# dat.to_excel(\"result_K_list.xlsx\")  \n",
    "# print(res_diffC)\n",
    "dat = pd.DataFrame(res_diffC)\n",
    "# print(dat)\n",
    "dat1 = round(dat,3)\n",
    "\n",
    "\n",
    "for i in range(1,5):\n",
    "    dat1.iloc[:,i] = [str(a) +'('+ str(b)+\")\" for a,b in zip(dat1.iloc[:,i],dat1.iloc[:,i+4])]\n",
    "print(dat1)\n",
    "col = dat1.columns.tolist()\n",
    "col = [col[0],col[4],col[1],col[2],col[3]]\n",
    "print(col)\n",
    "print(dat1[col])\n",
    "print(os.getcwd())\n",
    "dat2=dat1[col]\n",
    "print(dat2)\n",
    "dat2.to_excel('results/2x3/res_changepointsepar_K_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e429605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        C changepoint_err   cluster_err     iter_num        bestK  cp_var  \\\n",
      "0     0.0    0.098(0.006)  0.955(0.005)  2.89(0.518)  3.26(0.292)   0.006   \n",
      "1     0.1    0.098(0.006)  0.955(0.005)  2.89(0.518)  3.26(0.292)   0.006   \n",
      "2     1.0    0.098(0.006)  0.955(0.005)  2.89(0.518)  3.26(0.292)   0.006   \n",
      "3    10.0    0.098(0.006)  0.955(0.005)  2.89(0.518)  3.26(0.292)   0.006   \n",
      "4   100.0    0.098(0.006)  0.955(0.005)  2.89(0.518)  3.26(0.292)   0.006   \n",
      "5  1000.0    0.208(0.003)  0.763(0.018)    3.5(0.47)  4.16(1.354)   0.003   \n",
      "\n",
      "   cluster_var  iter_num_var  bestK_var  \n",
      "0        0.005         0.518      0.292  \n",
      "1        0.005         0.518      0.292  \n",
      "2        0.005         0.518      0.292  \n",
      "3        0.005         0.518      0.292  \n",
      "4        0.005         0.518      0.292  \n",
      "5        0.018         0.470      1.354  \n"
     ]
    }
   ],
   "source": [
    "# oracle changepoints\n",
    "C_list =[0, 0.1, 1, 10,100, 1000]\n",
    "M=100\n",
    "# ic\n",
    "init=\"changepoints\"\n",
    "K_list = [3]\n",
    "ic_list = np.zeros(1)\n",
    "loss_mat = np.zeros([M, 1])\n",
    "Kl_mat = np.zeros([M, 1])\n",
    "c_mat = np.zeros([M, 1])\n",
    "init = \"initchangepoints\"\n",
    "\n",
    "for seed in range(100):\n",
    "    for K in K_list:\n",
    "        setpath(trans_setting, K = K, string=init)\n",
    "        file_name = \"seed_\"+str(seed)+\".dat\"\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        t = pickle.load(pkl_file)\n",
    "        # ic_list[K_list.index(K)] = uti.IC(t['loss'], t['changepoint'], \n",
    "        #                               t['group'], N, T, K, C)\n",
    "        loss_mat[seed, K_list.index(K)] = t['loss']\n",
    "        Kl_mat[seed, K_list.index(K)] =  K*np.log(np.sum(T-1 -t['changepoint']))\n",
    "        Ck, indicesList, occurCount = np.unique(t['group'], return_index = True,return_counts=True)\n",
    "        c_mat[seed, K_list.index(K)] = occurCount.dot((T-1 -t['changepoint'])[np.s_[indicesList]])/(N*T)*np.log(np.sum(T-1 -t['changepoint']))\n",
    "        pkl_file.close()\n",
    "\n",
    "res_diffC = [None] * len(C_list)\n",
    "for C in C_list:\n",
    "    bestK_list = np.zeros(M)\n",
    "    changepoint_err_list = []\n",
    "    cluster_err_list= []\n",
    "    iter_num =[]\n",
    "    for seed in range(M):\n",
    "        ic_list = loss_mat[seed, :] - Kl_mat[seed, :] + c_mat[seed,:]*C\n",
    "        bestK = K_list[np.where(ic_list == max(ic_list))[0][0]]\n",
    "        bestK_list[seed]=bestK\n",
    "        setpath(trans_setting, K = bestK)\n",
    "        file_name = \"seed_\"+str(seed)+\".dat\"\n",
    "        pkl_file = open(file_name, 'rb')\n",
    "        t = pickle.load(pkl_file)\n",
    "        changepoint_err, cluster_err = evaluate(changepoints_true.squeeze(), t['group'].squeeze(),\n",
    "                                                t['changepoint'].squeeze(), N, T)\n",
    "        changepoint_err_list.append(changepoint_err)\n",
    "        cluster_err_list.append(cluster_err)\n",
    "        iter_num.append(t['iter_num'])\n",
    "        pkl_file.close()\n",
    "    res_diffC[C_list.index(C)] = {\"C\":C,\n",
    "                                  \"changepoint_err\": np.mean(changepoint_err_list),\n",
    "                                  \"cluster_err\": np.mean(cluster_err_list),\n",
    "                                  \"iter_num\":np.mean(iter_num),\n",
    "                                  \"bestK\":np.mean(bestK_list),\n",
    "                                  \"cp_var\":np.var(changepoint_err_list),\n",
    "                                  'cluster_var':np.var(cluster_err_list),\n",
    "                                  'iter_num_var':np.var(iter_num),\n",
    "                                  'bestK_var':np.var(bestK_list)}\n",
    "\n",
    "# dat = pd.DataFrame(res_diffC)\n",
    "# dat.to_excel(\"result_K_list.xlsx\")  \n",
    "# print(res_diffC)\n",
    "dat = pd.DataFrame(res_diffC)\n",
    "# print(dat)\n",
    "dat1 = round(dat,3)\n",
    "\n",
    "\n",
    "for i in range(1,5):\n",
    "    dat1.iloc[:,i] = [str(a) +'('+ str(b)+\")\" for a,b in zip(dat1.iloc[:,i],dat1.iloc[:,i+4])]\n",
    "print(dat1)\n",
    "col = dat1.columns.tolist()\n",
    "col = [col[0],col[4],col[1],col[2],col[3]]\n",
    "print(col)\n",
    "print(dat1[col])\n",
    "print(os.getcwd())\n",
    "dat2=dat1[col]\n",
    "print(dat2)\n",
    "dat2.to_excel('results/2x3/res_changepointsepar_K_list.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
